{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26192b76",
      "metadata": {
        "id": "26192b76"
      },
      "outputs": [],
      "source": [
        "# importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from collections import Counter\n",
        "from prettytable import PrettyTable\n",
        "from time import time\n",
        "import datetime\n",
        "from pandas.api.types import is_string_dtype\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from prettytable import PrettyTable\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import TimeSeriesSplit, train_test_split, GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1HczaP3NI7b",
        "outputId": "41472cc1-d948-4d33-902e-dcf460faa230"
      },
      "id": "m1HczaP3NI7b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbfbea3d",
      "metadata": {
        "id": "fbfbea3d"
      },
      "outputs": [],
      "source": [
        "# reading the datasets\n",
        "df_train_transaction = pd.read_csv(\"/content/drive/MyDrive/Self_Case_Study_1/Datasets/ieee-fraud-detection/train_transaction.csv\")\n",
        "df_train_identity = pd.read_csv(\"/content/drive/MyDrive/Self_Case_Study_1/Datasets/ieee-fraud-detection/train_identity.csv\")\n",
        "df_test_transaction = pd.read_csv(\"/content/drive/MyDrive/Self_Case_Study_1/Datasets/ieee-fraud-detection/test_transaction.csv\")\n",
        "df_test_identity = pd.read_csv(\"/content/drive/MyDrive/Self_Case_Study_1/Datasets/ieee-fraud-detection/test_identity.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "797e9b9e",
      "metadata": {
        "id": "797e9b9e",
        "outputId": "6596592d-82e5-4e0f-db93-fa8b59bf12c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of train_transaction dataset: (590540, 394)\n",
            "shape of train_identity dataset: (144233, 41)\n",
            "shape of test_transaction dataset: (506691, 393)\n",
            "shape of test_identity dataset: (141907, 41)\n"
          ]
        }
      ],
      "source": [
        "#getting the shape of each train dataset and test dataset\n",
        "print(\"shape of train_transaction dataset:\", df_train_transaction.shape)\n",
        "print(\"shape of train_identity dataset:\", df_train_identity.shape)\n",
        "print(\"shape of test_transaction dataset:\", df_test_transaction.shape)\n",
        "print(\"shape of test_identity dataset:\", df_test_identity.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8b27e0a",
      "metadata": {
        "id": "b8b27e0a"
      },
      "outputs": [],
      "source": [
        "# merging transaction and identity data\n",
        "df_train = df_train_transaction.merge(df_train_identity, on = 'TransactionID', how = 'left')\n",
        "target = df_train['isFraud']     #storing class label inside a 'target' variable\n",
        "# df_train.drop(['isFraud'], axis=1, inplace = True)   \n",
        "\n",
        "df_test = df_test_transaction.merge(df_test_identity, on = 'TransactionID', how = 'left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbf9014c",
      "metadata": {
        "id": "fbf9014c",
        "outputId": "1ce0fd66-3087-4f37-c562-37e2655ace78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of training dataset: (590540, 434)\n",
            "shape of test dataset: (506691, 433)\n"
          ]
        }
      ],
      "source": [
        "# getting the shape of the dataset after merging\n",
        "print('shape of training dataset:', df_train.shape)\n",
        "print('shape of test dataset:', df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e1afdfd",
      "metadata": {
        "id": "2e1afdfd",
        "outputId": "eea61264-cd72-47f9-9cc9-13da1d9fc257",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
            "0        2987000        0          86400            68.5         W  13926   \n",
            "1        2987001        0          86401            29.0         W   2755   \n",
            "2        2987002        0          86469            59.0         W   4663   \n",
            "3        2987003        0          86499            50.0         W  18132   \n",
            "\n",
            "   card2  card3       card4  card5  ... id_31  id_32  id_33  id_34  id_35  \\\n",
            "0    NaN  150.0    discover  142.0  ...   NaN    NaN    NaN    NaN    NaN   \n",
            "1  404.0  150.0  mastercard  102.0  ...   NaN    NaN    NaN    NaN    NaN   \n",
            "2  490.0  150.0        visa  166.0  ...   NaN    NaN    NaN    NaN    NaN   \n",
            "3  567.0  150.0  mastercard  117.0  ...   NaN    NaN    NaN    NaN    NaN   \n",
            "\n",
            "  id_36 id_37  id_38  DeviceType  DeviceInfo  \n",
            "0   NaN   NaN    NaN         NaN         NaN  \n",
            "1   NaN   NaN    NaN         NaN         NaN  \n",
            "2   NaN   NaN    NaN         NaN         NaN  \n",
            "3   NaN   NaN    NaN         NaN         NaN  \n",
            "\n",
            "[4 rows x 434 columns]\n",
            "================================================================================\n",
            "   TransactionID  TransactionDT  TransactionAmt ProductCD  card1  card2  \\\n",
            "0        3663549       18403224           31.95         W  10409  111.0   \n",
            "1        3663550       18403263           49.00         W   4272  111.0   \n",
            "2        3663551       18403310          171.00         W   4476  574.0   \n",
            "3        3663552       18403310          284.95         W  10989  360.0   \n",
            "\n",
            "   card3 card4  card5  card6  ...  id-31  id-32  id-33  id-34 id-35 id-36  \\\n",
            "0  150.0  visa  226.0  debit  ...    NaN    NaN    NaN    NaN   NaN   NaN   \n",
            "1  150.0  visa  226.0  debit  ...    NaN    NaN    NaN    NaN   NaN   NaN   \n",
            "2  150.0  visa  226.0  debit  ...    NaN    NaN    NaN    NaN   NaN   NaN   \n",
            "3  150.0  visa  166.0  debit  ...    NaN    NaN    NaN    NaN   NaN   NaN   \n",
            "\n",
            "   id-37  id-38  DeviceType  DeviceInfo  \n",
            "0    NaN    NaN         NaN         NaN  \n",
            "1    NaN    NaN         NaN         NaN  \n",
            "2    NaN    NaN         NaN         NaN  \n",
            "3    NaN    NaN         NaN         NaN  \n",
            "\n",
            "[4 rows x 433 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df_train.head(4))\n",
        "print('='*80)\n",
        "print(df_test.head(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c16d7371",
      "metadata": {
        "id": "c16d7371",
        "outputId": "b60090da-5f2a-4d10-be29-d3252fdcc48a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt',\n",
            "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5',\n",
            "       ...\n",
            "       'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
            "       'DeviceType', 'DeviceInfo'],\n",
            "      dtype='object', length=434)\n",
            "================================================================================\n",
            "Index(['TransactionID', 'TransactionDT', 'TransactionAmt', 'ProductCD',\n",
            "       'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n",
            "       ...\n",
            "       'id-31', 'id-32', 'id-33', 'id-34', 'id-35', 'id-36', 'id-37', 'id-38',\n",
            "       'DeviceType', 'DeviceInfo'],\n",
            "      dtype='object', length=433)\n"
          ]
        }
      ],
      "source": [
        "print(df_train.columns)\n",
        "print('='*80)\n",
        "print(df_test.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92423930",
      "metadata": {
        "id": "92423930"
      },
      "source": [
        "We observed that The names of the id features in test dataset and train dataset did not match. While id features in the test dataset were of the form id-x, they were present in the train dataset with the name id_x, where x was a number between 01 and 38. and as a result, we will convert the test dataset's id feature names from id-x to id_x."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceb0b15b",
      "metadata": {
        "id": "ceb0b15b"
      },
      "outputs": [],
      "source": [
        "# converting the test dataset's id feature names from id-x to id_x\n",
        "for i in df_test.columns:\n",
        "    k = i.replace('-', '_')\n",
        "    df_test.rename(columns = {i:k}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6dedf82",
      "metadata": {
        "id": "f6dedf82",
        "outputId": "da34c437-616f-4456-92aa-724694d0ca56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt',\n",
            "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5',\n",
            "       ...\n",
            "       'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
            "       'DeviceType', 'DeviceInfo'],\n",
            "      dtype='object', length=434)\n",
            "==================================================\n",
            "Index(['TransactionID', 'TransactionDT', 'TransactionAmt', 'ProductCD',\n",
            "       'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n",
            "       ...\n",
            "       'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
            "       'DeviceType', 'DeviceInfo'],\n",
            "      dtype='object', length=433)\n"
          ]
        }
      ],
      "source": [
        "print(df_train.columns)\n",
        "print('='*50)\n",
        "print(df_test.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3f00601",
      "metadata": {
        "id": "e3f00601"
      },
      "source": [
        "### Missing data and duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "844d8e9a",
      "metadata": {
        "id": "844d8e9a",
        "outputId": "5726a87f-5fce-459a-9f8c-15efb29a558b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id_24</th>\n",
              "      <td>585793</td>\n",
              "      <td>0.991962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_25</th>\n",
              "      <td>585408</td>\n",
              "      <td>0.991310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_07</th>\n",
              "      <td>585385</td>\n",
              "      <td>0.991271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_08</th>\n",
              "      <td>585385</td>\n",
              "      <td>0.991271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_21</th>\n",
              "      <td>585381</td>\n",
              "      <td>0.991264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_26</th>\n",
              "      <td>585377</td>\n",
              "      <td>0.991257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_27</th>\n",
              "      <td>585371</td>\n",
              "      <td>0.991247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_23</th>\n",
              "      <td>585371</td>\n",
              "      <td>0.991247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_22</th>\n",
              "      <td>585371</td>\n",
              "      <td>0.991247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dist2</th>\n",
              "      <td>552913</td>\n",
              "      <td>0.936284</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Total   Percent\n",
              "id_24  585793  0.991962\n",
              "id_25  585408  0.991310\n",
              "id_07  585385  0.991271\n",
              "id_08  585385  0.991271\n",
              "id_21  585381  0.991264\n",
              "id_26  585377  0.991257\n",
              "id_27  585371  0.991247\n",
              "id_23  585371  0.991247\n",
              "id_22  585371  0.991247\n",
              "dist2  552913  0.936284"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# getting the missing data from train dataset\n",
        "total = df_train.isnull().sum().sort_values(ascending=False)\n",
        "percent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)\n",
        "missing_data_train = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "missing_data_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f885f02",
      "metadata": {
        "id": "0f885f02",
        "outputId": "46032a96-0605-4de7-b8cb-053ac1978f90"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id_24</th>\n",
              "      <td>501951</td>\n",
              "      <td>0.990645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_25</th>\n",
              "      <td>501652</td>\n",
              "      <td>0.990055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_26</th>\n",
              "      <td>501644</td>\n",
              "      <td>0.990039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_21</th>\n",
              "      <td>501632</td>\n",
              "      <td>0.990016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_08</th>\n",
              "      <td>501632</td>\n",
              "      <td>0.990016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_07</th>\n",
              "      <td>501632</td>\n",
              "      <td>0.990016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_27</th>\n",
              "      <td>501629</td>\n",
              "      <td>0.990010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_23</th>\n",
              "      <td>501629</td>\n",
              "      <td>0.990010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_22</th>\n",
              "      <td>501629</td>\n",
              "      <td>0.990010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dist2</th>\n",
              "      <td>470255</td>\n",
              "      <td>0.928090</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Total   Percent\n",
              "id_24  501951  0.990645\n",
              "id_25  501652  0.990055\n",
              "id_26  501644  0.990039\n",
              "id_21  501632  0.990016\n",
              "id_08  501632  0.990016\n",
              "id_07  501632  0.990016\n",
              "id_27  501629  0.990010\n",
              "id_23  501629  0.990010\n",
              "id_22  501629  0.990010\n",
              "dist2  470255  0.928090"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# getting the missing data from test dataset\n",
        "total = df_test.isnull().sum().sort_values(ascending=False)\n",
        "percent = (df_test.isnull().sum()/df_test.isnull().count()).sort_values(ascending=False)\n",
        "missing_data_test = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "missing_data_test.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91c353be",
      "metadata": {
        "id": "91c353be",
        "outputId": "51fba94f-f76a-4563-83fe-981e7d9a0675"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of duplicate rows in train dataset: 0\n",
            "number of duplicate rows in test dataset: 0\n"
          ]
        }
      ],
      "source": [
        "## duplicates in dataset\n",
        "print(\"number of duplicate rows in train dataset:\", df_train.duplicated().sum())\n",
        "print(\"number of duplicate rows in test dataset:\", df_test.duplicated().sum())\n",
        "\n",
        "# No duplicates found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed2ed9d2",
      "metadata": {
        "id": "ed2ed9d2"
      },
      "outputs": [],
      "source": [
        "# available categorical features\n",
        "cat_fea = ['ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', \n",
        "           'P_emaildomain', 'R_emaildomain', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', \n",
        "           'DeviceType', 'DeviceInfo', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', \n",
        "           'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', \n",
        "           'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99b0d869",
      "metadata": {
        "id": "99b0d869"
      },
      "outputs": [],
      "source": [
        "# available numerical features\n",
        "num_fea =  ['TransactionDT', 'TransactionAmt', 'dist1', 'dist2','C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', \n",
        "                 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7','D8', 'D9', 'D10', 'D11', \n",
        "                 'D12', 'D13', 'D14', 'D15', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', \n",
        "                 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', \n",
        "                 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', \n",
        "                 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', \n",
        "                 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', \n",
        "                 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', \n",
        "                 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', \n",
        "                 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', \n",
        "                 'V102', 'V103', 'V104', 'V105', 'V106', 'V107','V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', \n",
        "                 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', \n",
        "                 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V138', \n",
        "                 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', \n",
        "                 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', \n",
        "                 'V163', 'V164', 'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174', \n",
        "                 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', \n",
        "                 'V187', 'V188', 'V189', 'V190', 'V191', 'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', \n",
        "                 'V199', 'V200', 'V201', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209', 'V210', \n",
        "                 'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218', 'V219', 'V220', 'V221', 'V222', \n",
        "                 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', \n",
        "                 'V235', 'V236', 'V237', 'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245', 'V246', \n",
        "                 'V247', 'V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255', 'V256', 'V257', 'V258', \n",
        "                 'V259', 'V260', 'V261', 'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V269', 'V270', \n",
        "                 'V271', 'V272', 'V273', 'V274', 'V275', 'V276', 'V277', 'V278', 'V279', 'V280', 'V281', 'V282', \n",
        "                 'V283', 'V284', 'V285', 'V286', 'V287', 'V288', 'V289', 'V290', 'V291', 'V292', 'V293', 'V294', \n",
        "                 'V295', 'V296', 'V297', 'V298', 'V299', 'V300', 'V301', 'V302', 'V303', 'V304', 'V305', 'V306', \n",
        "                 'V307', 'V308', 'V309', 'V310', 'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318', \n",
        "                 'V319', 'V320', 'V321', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', \n",
        "                 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339', 'id_01', 'id_02', 'id_03', \n",
        "                 'id_04', 'id_05', 'id_06','id_07','id_08' 'id_09', 'id_10', 'id_11']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15bf2268",
      "metadata": {
        "id": "15bf2268"
      },
      "outputs": [],
      "source": [
        "# data preprocessing\n",
        "def preprocessing(data, feature):\n",
        "    data[feature] = data[feature].str.replace(' ','_')\n",
        "    data[feature]= data[feature].str.replace('-','_')\n",
        "    data[feature] = data[feature].str.replace('/','_')\n",
        "    \n",
        "    return data[feature]\n",
        "\n",
        "# preprocessing of few categorical columns\n",
        "\n",
        "df_train['DeviceInfo'] = preprocessing(df_train, 'DeviceInfo')\n",
        "df_test['DeviceInfo'] = preprocessing(df_test, 'DeviceInfo')\n",
        "\n",
        "df_train['card4'] = preprocessing(df_train, 'card4')\n",
        "df_test['card4'] = preprocessing(df_test, 'card4')\n",
        "\n",
        "df_train['card6'] = preprocessing(df_train, 'card6')\n",
        "df_test['card6'] = preprocessing(df_test, 'card6')\n",
        "\n",
        "df_train['id_30'] = preprocessing(df_train, 'id_30')\n",
        "df_test['id_30'] = preprocessing(df_test, 'id_30')\n",
        "\n",
        "df_train['id_31'] = preprocessing(df_train, 'id_31')\n",
        "df_test['id_31'] = preprocessing(df_test, 'id_31')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17c5fa37",
      "metadata": {
        "id": "17c5fa37"
      },
      "source": [
        "### Spliting the dataset into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "174d4685",
      "metadata": {
        "id": "174d4685"
      },
      "outputs": [],
      "source": [
        "x_train = df_train.drop(['isFraud', 'TransactionID'], axis=1)\n",
        "y_train = df_train['isFraud']\n",
        "\n",
        "x_test = df_test.drop(['TransactionID'], axis=1)\n",
        "test_ids = df_test['TransactionID'].values\n",
        "\n",
        "del df_train, df_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dc6ae9b",
      "metadata": {
        "id": "5dc6ae9b"
      },
      "source": [
        "### Encoding & scaling the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74a3fb2b",
      "metadata": {
        "id": "74a3fb2b"
      },
      "outputs": [],
      "source": [
        "def label_encoding(X_train, X_test, cat_features):\n",
        "    \n",
        "    '''\n",
        "    Utility Function to Encode Categorical Features.\n",
        "    '''\n",
        "    \n",
        "    for fea in cat_features:\n",
        "        X_train[fea] = X_train[fea].astype(str)\n",
        "        X_test[fea] = X_test[fea].astype(str)\n",
        "    \n",
        "        label_enc = LabelEncoder()\n",
        "        label_enc.fit(X_train[fea])\n",
        "        mapping = dict(zip(label_enc.classes_, label_enc.transform(label_enc.classes_)))\n",
        "        X_train[fea] = label_enc.transform(X_train[fea])\n",
        "    \n",
        "        # Manually Encoding the CV and Test Dataset so as to avoid error for any category which is not present in train set\n",
        "    \n",
        "        # All the categories which are not present in train datset are encoded as -1\n",
        "    \n",
        "        X_test[fea] = [-1 if mapping.get(val, -1)==-1 else mapping[val] for val in X_test[fea].values]\n",
        " \n",
        "\n",
        "    return (X_train, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "796afe75",
      "metadata": {
        "id": "796afe75"
      },
      "outputs": [],
      "source": [
        "# normalization using minmaxscaler\n",
        "\n",
        "def min_max_scaler(X_train, X_test):\n",
        "    \n",
        "    X_train_norm = X_train.copy()\n",
        "    X_test_norm = X_test.copy()\n",
        "    \n",
        "    for fea in X_train.columns:\n",
        "        if fea not in cat_fea:\n",
        "            scale = MinMaxScaler()\n",
        "            X_train_norm[fea] = scale.fit_transform(X_train_norm[fea].values.reshape(-1, 1))\n",
        "            X_test_norm[fea] = scale.transform(X_test_norm[fea].values.reshape(-1, 1))\n",
        "            X_train_norm[fea].fillna(-1,inplace=True)\n",
        "            X_test_norm[fea].fillna(-1,inplace=True)\n",
        "\n",
        "    return (X_train_norm, X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a35a1c3",
      "metadata": {
        "id": "1a35a1c3"
      },
      "outputs": [],
      "source": [
        "# function to save test predictions in a file\n",
        "\n",
        "def predict_and_save(prediction, name):\n",
        "    \n",
        "    '''\n",
        "        Utility Function to save the test data predictions locally.\n",
        "    '''\n",
        "\n",
        "    df = pd.DataFrame({'TransactionID':test_ids.reshape(-1), 'isFraud':prediction.reshape(-1)})\n",
        "    df = df.sort_values('TransactionID')\n",
        "    df.to_csv(name, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84d83e74",
      "metadata": {
        "id": "84d83e74"
      },
      "outputs": [],
      "source": [
        "# Label Encoding Categorical Features\n",
        "x_train, x_test = label_encoding(x_train, x_test, cat_fea)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper-Parameter Tuning using RandomizedSearchCV"
      ],
      "metadata": {
        "id": "Umjuv38BFkf6"
      },
      "id": "Umjuv38BFkf6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "param_grid = {'learning_rate':[0.002, 0.02, 0.2],\n",
        "              'max_depth':[12, 16, 20],\n",
        "              'subsample': [0.4,0.6,0.8],\n",
        "              'colsample_bytree' : [0.4,0.6,0.8],\n",
        "              'n_estimators': [1000, 2000, 3000, 5000],\n",
        "              'tree_method': ['gpu_hist']}"
      ],
      "metadata": {
        "id": "uO9aaZYPMIp9"
      },
      "id": "uO9aaZYPMIp9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "clf = xgb.XGBClassifier()\n",
        "search = RandomizedSearchCV(clf, param_grid, n_iter=6, verbose=20, cv=3, \n",
        "                            scoring='roc_auc', return_train_score=True, random_state = 10)\n",
        "\n",
        "search.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "id": "bXFZ9BzlMItj",
        "outputId": "941cd75f-b000-47e7-d662-c7dc9f4d34c0"
      },
      "id": "bXFZ9BzlMItj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "[CV 1/3; 1/6] START colsample_bytree=0.8, learning_rate=0.002, max_depth=12, n_estimators=2000, subsample=0.4, tree_method=gpu_hist\n",
            "[CV 1/3; 1/6] END colsample_bytree=0.8, learning_rate=0.002, max_depth=12, n_estimators=2000, subsample=0.4, tree_method=gpu_hist;, score=(train=0.960, test=0.873) total time= 3.2min\n",
            "[CV 2/3; 1/6] START colsample_bytree=0.8, learning_rate=0.002, max_depth=12, n_estimators=2000, subsample=0.4, tree_method=gpu_hist\n",
            "[CV 2/3; 1/6] END colsample_bytree=0.8, learning_rate=0.002, max_depth=12, n_estimators=2000, subsample=0.4, tree_method=gpu_hist;, score=(train=0.962, test=0.884) total time= 3.4min\n",
            "[CV 3/3; 1/6] START colsample_bytree=0.8, learning_rate=0.002, max_depth=12, n_estimators=2000, subsample=0.4, tree_method=gpu_hist\n",
            "[CV 3/3; 1/6] END colsample_bytree=0.8, learning_rate=0.002, max_depth=12, n_estimators=2000, subsample=0.4, tree_method=gpu_hist;, score=(train=0.958, test=0.893) total time= 3.4min\n",
            "[CV 1/3; 2/6] START colsample_bytree=0.6, learning_rate=0.002, max_depth=16, n_estimators=3000, subsample=0.6, tree_method=gpu_hist\n",
            "[CV 1/3; 2/6] END colsample_bytree=0.6, learning_rate=0.002, max_depth=16, n_estimators=3000, subsample=0.6, tree_method=gpu_hist;, score=(train=0.994, test=0.888) total time= 7.4min\n",
            "[CV 2/3; 2/6] START colsample_bytree=0.6, learning_rate=0.002, max_depth=16, n_estimators=3000, subsample=0.6, tree_method=gpu_hist\n",
            "[CV 2/3; 2/6] END colsample_bytree=0.6, learning_rate=0.002, max_depth=16, n_estimators=3000, subsample=0.6, tree_method=gpu_hist;, score=(train=0.996, test=0.892) total time= 7.8min\n",
            "[CV 3/3; 2/6] START colsample_bytree=0.6, learning_rate=0.002, max_depth=16, n_estimators=3000, subsample=0.6, tree_method=gpu_hist\n",
            "[CV 3/3; 2/6] END colsample_bytree=0.6, learning_rate=0.002, max_depth=16, n_estimators=3000, subsample=0.6, tree_method=gpu_hist;, score=(train=0.995, test=0.906) total time= 7.8min\n",
            "[CV 1/3; 3/6] START colsample_bytree=0.4, learning_rate=0.002, max_depth=20, n_estimators=1000, subsample=0.4, tree_method=gpu_hist\n",
            "[CV 1/3; 3/6] END colsample_bytree=0.4, learning_rate=0.002, max_depth=20, n_estimators=1000, subsample=0.4, tree_method=gpu_hist;, score=(train=0.949, test=0.872) total time= 2.3min\n",
            "[CV 2/3; 3/6] START colsample_bytree=0.4, learning_rate=0.002, max_depth=20, n_estimators=1000, subsample=0.4, tree_method=gpu_hist\n",
            "[CV 2/3; 3/6] END colsample_bytree=0.4, learning_rate=0.002, max_depth=20, n_estimators=1000, subsample=0.4, tree_method=gpu_hist;, score=(train=0.949, test=0.893) total time= 2.3min\n",
            "[CV 3/3; 3/6] START colsample_bytree=0.4, learning_rate=0.002, max_depth=20, n_estimators=1000, subsample=0.4, tree_method=gpu_hist\n",
            "[CV 3/3; 3/6] END colsample_bytree=0.4, learning_rate=0.002, max_depth=20, n_estimators=1000, subsample=0.4, tree_method=gpu_hist;, score=(train=0.945, test=0.882) total time= 2.3min\n",
            "[CV 1/3; 4/6] START colsample_bytree=0.6, learning_rate=0.002, max_depth=20, n_estimators=3000, subsample=0.6, tree_method=gpu_hist\n",
            "[CV 1/3; 4/6] END colsample_bytree=0.6, learning_rate=0.002, max_depth=20, n_estimators=3000, subsample=0.6, tree_method=gpu_hist;, score=(train=0.998, test=0.886) total time= 9.2min\n",
            "[CV 2/3; 4/6] START colsample_bytree=0.6, learning_rate=0.002, max_depth=20, n_estimators=3000, subsample=0.6, tree_method=gpu_hist\n",
            "[CV 2/3; 4/6] END colsample_bytree=0.6, learning_rate=0.002, max_depth=20, n_estimators=3000, subsample=0.6, tree_method=gpu_hist;, score=(train=0.998, test=0.894) total time= 9.7min\n",
            "[CV 3/3; 4/6] START colsample_bytree=0.6, learning_rate=0.002, max_depth=20, n_estimators=3000, subsample=0.6, tree_method=gpu_hist\n",
            "[CV 3/3; 4/6] END colsample_bytree=0.6, learning_rate=0.002, max_depth=20, n_estimators=3000, subsample=0.6, tree_method=gpu_hist;, score=(train=0.998, test=0.907) total time= 9.6min\n",
            "[CV 1/3; 5/6] START colsample_bytree=0.4, learning_rate=0.2, max_depth=20, n_estimators=1000, subsample=0.8, tree_method=gpu_hist\n",
            "[CV 1/3; 5/6] END colsample_bytree=0.4, learning_rate=0.2, max_depth=20, n_estimators=1000, subsample=0.8, tree_method=gpu_hist;, score=(train=1.000, test=0.884) total time= 1.9min\n",
            "[CV 2/3; 5/6] START colsample_bytree=0.4, learning_rate=0.2, max_depth=20, n_estimators=1000, subsample=0.8, tree_method=gpu_hist\n",
            "[CV 2/3; 5/6] END colsample_bytree=0.4, learning_rate=0.2, max_depth=20, n_estimators=1000, subsample=0.8, tree_method=gpu_hist;, score=(train=1.000, test=0.904) total time= 1.9min\n",
            "[CV 3/3; 5/6] START colsample_bytree=0.4, learning_rate=0.2, max_depth=20, n_estimators=1000, subsample=0.8, tree_method=gpu_hist\n",
            "[CV 3/3; 5/6] END colsample_bytree=0.4, learning_rate=0.2, max_depth=20, n_estimators=1000, subsample=0.8, tree_method=gpu_hist;, score=(train=1.000, test=0.898) total time= 1.9min\n",
            "[CV 1/3; 6/6] START colsample_bytree=0.4, learning_rate=0.002, max_depth=12, n_estimators=1000, subsample=0.6, tree_method=gpu_hist\n",
            "[CV 1/3; 6/6] END colsample_bytree=0.4, learning_rate=0.002, max_depth=12, n_estimators=1000, subsample=0.6, tree_method=gpu_hist;, score=(train=0.923, test=0.866) total time= 1.6min\n",
            "[CV 2/3; 6/6] START colsample_bytree=0.4, learning_rate=0.002, max_depth=12, n_estimators=1000, subsample=0.6, tree_method=gpu_hist\n",
            "[CV 2/3; 6/6] END colsample_bytree=0.4, learning_rate=0.002, max_depth=12, n_estimators=1000, subsample=0.6, tree_method=gpu_hist;, score=(train=0.921, test=0.888) total time= 1.5min\n",
            "[CV 3/3; 6/6] START colsample_bytree=0.4, learning_rate=0.002, max_depth=12, n_estimators=1000, subsample=0.6, tree_method=gpu_hist\n",
            "[CV 3/3; 6/6] END colsample_bytree=0.4, learning_rate=0.002, max_depth=12, n_estimators=1000, subsample=0.6, tree_method=gpu_hist;, score=(train=0.919, test=0.878) total time= 1.5min\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3,\n",
              "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                           callbacks=None,\n",
              "                                           colsample_bylevel=None,\n",
              "                                           colsample_bynode=None,\n",
              "                                           colsample_bytree=None,\n",
              "                                           early_stopping_rounds=None,\n",
              "                                           enable_categorical=False,\n",
              "                                           eval_metric=None, feature_types=None,\n",
              "                                           gamma=None, gpu_id=None,\n",
              "                                           grow_policy=None,\n",
              "                                           importance_type=None,\n",
              "                                           interaction_constraints=None,\n",
              "                                           learning_rate...\n",
              "                                           n_estimators=100, n_jobs=None,\n",
              "                                           num_parallel_tree=None,\n",
              "                                           predictor=None, random_state=None, ...),\n",
              "                   n_iter=6,\n",
              "                   param_distributions={'colsample_bytree': [0.4, 0.6, 0.8],\n",
              "                                        'learning_rate': [0.002, 0.02, 0.2],\n",
              "                                        'max_depth': [12, 16, 20],\n",
              "                                        'n_estimators': [1000, 2000, 3000,\n",
              "                                                         5000],\n",
              "                                        'subsample': [0.4, 0.6, 0.8],\n",
              "                                        'tree_method': ['gpu_hist']},\n",
              "                   random_state=10, return_train_score=True, scoring='roc_auc',\n",
              "                   verbose=20)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
              "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                           callbacks=None,\n",
              "                                           colsample_bylevel=None,\n",
              "                                           colsample_bynode=None,\n",
              "                                           colsample_bytree=None,\n",
              "                                           early_stopping_rounds=None,\n",
              "                                           enable_categorical=False,\n",
              "                                           eval_metric=None, feature_types=None,\n",
              "                                           gamma=None, gpu_id=None,\n",
              "                                           grow_policy=None,\n",
              "                                           importance_type=None,\n",
              "                                           interaction_constraints=None,\n",
              "                                           learning_rate...\n",
              "                                           n_estimators=100, n_jobs=None,\n",
              "                                           num_parallel_tree=None,\n",
              "                                           predictor=None, random_state=None, ...),\n",
              "                   n_iter=6,\n",
              "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.4, 0.6, 0.8],\n",
              "                                        &#x27;learning_rate&#x27;: [0.002, 0.02, 0.2],\n",
              "                                        &#x27;max_depth&#x27;: [12, 16, 20],\n",
              "                                        &#x27;n_estimators&#x27;: [1000, 2000, 3000,\n",
              "                                                         5000],\n",
              "                                        &#x27;subsample&#x27;: [0.4, 0.6, 0.8],\n",
              "                                        &#x27;tree_method&#x27;: [&#x27;gpu_hist&#x27;]},\n",
              "                   random_state=10, return_train_score=True, scoring=&#x27;roc_auc&#x27;,\n",
              "                   verbose=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
              "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                           callbacks=None,\n",
              "                                           colsample_bylevel=None,\n",
              "                                           colsample_bynode=None,\n",
              "                                           colsample_bytree=None,\n",
              "                                           early_stopping_rounds=None,\n",
              "                                           enable_categorical=False,\n",
              "                                           eval_metric=None, feature_types=None,\n",
              "                                           gamma=None, gpu_id=None,\n",
              "                                           grow_policy=None,\n",
              "                                           importance_type=None,\n",
              "                                           interaction_constraints=None,\n",
              "                                           learning_rate...\n",
              "                                           n_estimators=100, n_jobs=None,\n",
              "                                           num_parallel_tree=None,\n",
              "                                           predictor=None, random_state=None, ...),\n",
              "                   n_iter=6,\n",
              "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.4, 0.6, 0.8],\n",
              "                                        &#x27;learning_rate&#x27;: [0.002, 0.02, 0.2],\n",
              "                                        &#x27;max_depth&#x27;: [12, 16, 20],\n",
              "                                        &#x27;n_estimators&#x27;: [1000, 2000, 3000,\n",
              "                                                         5000],\n",
              "                                        &#x27;subsample&#x27;: [0.4, 0.6, 0.8],\n",
              "                                        &#x27;tree_method&#x27;: [&#x27;gpu_hist&#x27;]},\n",
              "                   random_state=10, return_train_score=True, scoring=&#x27;roc_auc&#x27;,\n",
              "                   verbose=20)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame.from_dict(search.cv_results_)\n",
        "train_auc= results['mean_train_score']\n",
        "train_auc_std= results['std_train_score']\n",
        "cv_auc = results['mean_test_score'] \n",
        "cv_auc_std = results['std_test_score']"
      ],
      "metadata": {
        "id": "s8oJiWR6E2Lp"
      },
      "id": "s8oJiWR6E2Lp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best Parameters:' , search.best_params_)\n",
        "print('Best Score:' , search.best_score_)"
      ],
      "metadata": {
        "id": "JqufZ3OtGRx2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb54256f-681d-4190-c549-7b7cdcb3943d"
      },
      "id": "JqufZ3OtGRx2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'tree_method': 'gpu_hist', 'subsample': 0.8, 'n_estimators': 1000, 'max_depth': 20, 'learning_rate': 0.2, 'colsample_bytree': 0.4}\n",
            "Best Score: 0.8954609389974263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate = search.best_params_['learning_rate']\n",
        "best_estimator = search.best_params_['n_estimators']\n",
        "best_depth = search.best_params_['max_depth']\n",
        "best_subsample = search.best_params_['subsample']\n",
        "best_colsample_bytree = search.best_params_['colsample_bytree']"
      ],
      "metadata": {
        "id": "ltIPlRAsGR0y"
      },
      "id": "ltIPlRAsGR0y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lPyuhiAvGSAL"
      },
      "id": "lPyuhiAvGSAL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nqDcCIZzE2QZ"
      },
      "id": "nqDcCIZzE2QZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}